

# üöÄ GSP103 - Dataproc: Inicio r√°pido con la consola

## üß† Objetivo

En este lab vas a aprender a:

- Conceder permisos a la cuenta de servicio.
- Crear un cl√∫ster de Dataproc.
- Ejecutar un trabajo de Spark desde la consola.
- Ver la salida del trabajo.
- Modificar el n√∫mero de nodos de trabajo.
- Validar tu comprensi√≥n mediante preguntas de opci√≥n m√∫ltiple.

---

## üîê Permisos a la cuenta de servicio

1. Ir al men√∫ de navegaci√≥n > **IAM & Admin** > **IAM**.
2. Hacer clic en el √≠cono del l√°piz al lado de la cuenta `compute@developer.gserviceaccount.com`.
3. Hacer clic en **+ ADD ANOTHER ROLE**.
4. Seleccionar el rol **Storage Admin**.
5. Hacer clic en **Save**.

   ![alt text](Imagenes/1.png)
    ![alt text](image.png)

---

## üß± Task 1: Crear un cl√∫ster

1. Ir al men√∫ de navegaci√≥n > **View all products** > **Dataproc** > **Clusters**.
2. Clic en **Create cluster** > **Cluster on Compute Engine**.
3. Configurar los siguientes campos:

| Campo                          | Valor                |
|-------------------------------|----------------------|
| Name                           | `example-cluster`    |
| Region                         | _(elegir regi√≥n)_    |
| Zone                           | _(elegir zona)_      |
| Primary disk type (Master)     | Standard Persistent Disk |
| Machine Series (Master)        | E2                   |
| Machine Type (Master)          | `e2-standard-2`      |
| Disk Size (Master)             | 30 GB                |
| Number of Worker Nodes         | 2                    |
| Primary disk type (Workers)    | Standard Persistent Disk |
| Machine Series (Workers)       | E2                   |
| Machine Type (Workers)         | `e2-standard-2`      |
| Disk Size (Workers)            | 30 GB                |
| Internal IP only               | ‚ùå Deseleccionar  (Customize cluster (optional))   |
                                
4. Clic en **Create**. Esperar a que el estado cambie a `Running`.

    ![alt text](Imagenes/3.png)



### **Cuando cre√°s un cluster de Dataproc, autom√°ticamente genera dos buckets de Cloud Storage si no los especific√°s vos manualmente.**

 Estos son:

| Bucket                 | ¬øPara qu√© sirve?                                                                                                                |
| ---------------------- | ------------------------------------------------------------------------------------------------------------------------------- |
| `dataproc-staging-...` | Se usa para almacenar archivos temporales que necesita el cluster para ejecutar jobs, como los JAR, archivos Python, o scripts. |
| `dataproc-temp-...`    | Se usa para archivos temporales generados durante la ejecuci√≥n de los jobs, por ejemplo, resultados intermedios.                |


‚öôÔ∏è ¬øPor qu√© los crea autom√°ticamente?

Dataproc necesita espacio para:

- Subir archivos que se van a usar en el job (como los .jar del ejemplo de SparkPi).

- Guardar resultados temporales o de staging durante la ejecuci√≥n de jobs distribuidos.

- Hacer logging y debugging (algunos jobs pueden volcar logs all√≠).

    ![alt text](Imagenes/4.png)
---

## üßÆ Task 2: Ejecutar un trabajo de Spark

1. Ir a la pesta√±a **Jobs** en Dataproc y hacer clic en **Submit Job**.
2. Completar con:

| Campo        | Valor                                             |
|--------------|---------------------------------------------------|
| Region       | _(la misma que en el cl√∫ster)_                   |
| Cluster      | `example-cluster`                                 |
| Job type     | `Spark`                                           |
| Main class   | `org.apache.spark.examples.SparkPi`              |
| Jar files    | `file:///usr/lib/spark/examples/jars/spark-examples.jar` |
| Arguments    | `1000` (n√∫mero de puntos a calcular)             |

3. Clic en **Submit**.


### üß© ¬øQu√© est√°s ejecutando?

Este Job ejecuta un ejemplo llamado SparkPi, que calcula un valor aproximado de œÄ (pi) usando el m√©todo de Monte Carlo. Es un ejemplo cl√°sico para mostrar c√≥mo Spark paraleliza el trabajo en un cl√∫ster.

### üìÑ Detalle del Job



| Campo          | Valor                                                    | ¬øQu√© significa?                                                                                     |
| -------------- | -------------------------------------------------------- | --------------------------------------------------------------------------------------------------- |
| **Region**     | (la misma que el cl√∫ster)                                | Asegura que el job se ejecute **donde est√° el cl√∫ster** para evitar errores o latencia.             |
| **Cluster**    | `example-cluster`                                        | El nombre del cl√∫ster Dataproc donde se ejecuta el job.                                             |
| **Job type**   | `Spark`                                                  | Tipo de trabajo: en este caso, un **programa Spark** (podr√≠a ser Hadoop, PySpark, etc.).            |
| **Main class** | `org.apache.spark.examples.SparkPi`                      | La clase principal del programa. En este caso, SparkPi (viene preinstalada como ejemplo).           |
| **Jar files**  | `file:///usr/lib/spark/examples/jars/spark-examples.jar` | El JAR que contiene el c√≥digo. Este es un ejemplo incluido por defecto en los cl√∫steres Dataproc.   |
| **Arguments**  | `1000`                                                   | Le dice al programa cu√°ntos puntos aleatorios generar para estimar Pi. A m√°s puntos, m√°s precisi√≥n. |



### ¬øC√≥mo funciona SparkPi?

Este job usa un algoritmo de Monte Carlo para estimar œÄ.

-  Spark divide ese trabajo entre los nodos del cl√∫ster, cada uno hace su parte y luego combinan los resultados.

### ¬øPara qu√© sirve?

- Es un ejemplo cl√°sico de procesamiento paralelo.

- Te muestra c√≥mo un job aprovecha los recursos distribuidos del cl√∫ster.

- Te ense√±a a usar argumentos, JARs, clases, etc., en un job Spark real.



---

## üîç Task 3: Ver la salida del job

1. Hacer clic en el ID del job en la lista.
2. Activar **LINE WRAP** para ver mejor la salida.
3. Buscar el valor estimado de **pi** en el log.


   ![alt text](Imagenes/5.png)
---

## üîÑ Task 4: Modificar el n√∫mero de workers

1. Ir a **Clusters**, hacer clic en `example-cluster`.
2. Ir a la pesta√±a **Configuration**, hacer clic en **Edit**.
3. Cambiar **Worker nodes** de 2 a **4**.
4. Clic en **Save**.

   Luego pod√©s volver a ejecutar el mismo job de Spark para probar el nuevo tama√±o del cl√∫ster.


   ![alt text](Imagenes/6.png)
---

